{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e4bc983-c537-4ecd-9f61-b64da15aa8e0",
   "metadata": {},
   "source": [
    "# Machine Learning with SAP Datasphere, Hands-On Workshop\n",
    "## Explore and prepare the data in SAP Datasphere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165fc1b-6a38-402c-a885-d9b9ee12b046",
   "metadata": {},
   "source": [
    "Retrieve the credentials to connect to SAP Datasphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc61e94-de9f-4ef0-a062-ef2861680f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = open('credentials.json', 'r')\n",
    "credentials = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6f915-95af-4c5b-9341-fbb7822a64d8",
   "metadata": {},
   "source": [
    "Establish a connection with SAP Datasphere. <font color='red'>Ensure that you updated the credentials.json file with the details of the Database User that you created earlier on.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7629d-a693-42e8-91fa-c90efac6da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hana_ml.dataframe as dataframe\n",
    "conn = dataframe.ConnectionContext(address  = credentials['hana_address'],\n",
    "                                   port     = credentials['hana_port'], \n",
    "                                   user     = credentials['hana_user'], \n",
    "                                   password = credentials['hana_password'], \n",
    "                                  )\n",
    "conn.connection.isconnected()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e3c400b-dcbf-4595-b146-c488aecc5fb4",
   "metadata": {},
   "source": [
    "Point a hana_ml DataFrame to the view in SAP Datasphere, which returns the data that was loaded in the  previous Notebook. The variable df_remote is a reference to the data, which remains in SAP Datasphere. This command does not extract the data from SAP Datasphere. We will use such hana_ml Dataframes extensively in this workshop as they allow to process the data in SAP Datasphere. <font color='red'>Ensure to change the schema paramter to your Datasphere user, ie schema='AC54952UXX'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ddda-4b60-4a7e-a2fc-8a0411a47fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote = conn.table('V_LucerneElectricity', schema='DSP_ML_HANDSON')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77b9e5e0-909b-4f67-90a8-e821fce8c947",
   "metadata": {},
   "source": [
    "Retrieve and display a few rows of data from SAP Datasphere. First restrict the hana_ml Dataframe to only 5 rows with the head()-method. Then download these 5 rows with the collect()-method into the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088778e-3534-4dc5-90b3-f8371dc867ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote.head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de6390-f1a9-4d97-b96b-74a5c66e29fd",
   "metadata": {},
   "source": [
    "Get a first overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0f36a-c57c-4dd3-9316-1d14ab506584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote.describe().collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "870b4113-1db3-44ea-9e85-72d120dc1431",
   "metadata": {},
   "source": [
    "All above statistics were calculated in SAP Datasphere. See the SELECT Statement that was created by the describe()-method and executed in SAP Datasphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363c362-2878-4d4c-80f8-bb1a631e9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_remote.describe().select_statement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19313aa4-8206-4e01-9e42-de3d30ed07dd",
   "metadata": {},
   "source": [
    "Retrieve and plot the most recent 100 data points (each data point corresponds to a 15-minute interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c2cc3-dd84-4b0a-a20c-198f2041080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_remote.sort('TIMESTAMP').tail(n=100, ref_col='TIMESTAMP').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06332250-cee0-4ad9-b643-b491faa04ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "sns.set(rc={'figure.figsize':(15,5)})\n",
    "sns.lineplot(data=df_data, x=\"TIMESTAMP\", y=\"CONSUMPTION\")\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d474dba5-bfd2-4008-aa1a-b6d0e52147f5",
   "metadata": {},
   "source": [
    "Add a column that standardises the TIMESTAMP column to the full hour, so  minutes 15, 30 and 45 are set to 0. This is done by subtracting the seconds that passed since the full hour. This column is part of the hana_ml Dataframe. The underlying table remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc128495-c103-46c3-9f93-8945b7997c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote = df_remote.select('*', (\"ADD_SECONDS(TIMESTAMP, -MINUTE(TIMESTAMP)*60)\", 'DATEHOUR'))\n",
    "df_remote.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "819c8f0d-f16c-439c-938f-ce93632978e2",
   "metadata": {},
   "source": [
    "Use the newly created column to aggregate the consumtion on the hour of the day, thereby adding the consumption from minutes 15, 30 and 45 to the corresponding full hour. This aggregation is done on the fly. The aggregate is not persisted as physical table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57930468-3ce1-4b7b-b10e-93268d76ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_agg = df_remote.agg([('sum', 'CONSUMPTION', 'CONSUMPTION_H')], group_by='DATEHOUR').sort('DATEHOUR')\n",
    "df_rem_agg.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3edabaa2",
   "metadata": {},
   "source": [
    "Display the SELECT statement that is underpinning the hana_ml DataFrame df_rem_agg. Notice the sum(\"CONSUMPTION\"), which creates the aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rem_agg.select_statement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "054af9e0-c264-47aa-a6cc-51ff7731aa7b",
   "metadata": {},
   "source": [
    "Add column that shows only the hour of the day. We use this column for further data analyis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bbacb-35c9-4567-b306-393b2817004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_agg = df_rem_agg.select('*', ('HOUR(DATEHOUR)', 'HOUR'))\n",
    "df_rem_agg.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "336371c6-eda0-42e6-ad7d-b2bb7f762428",
   "metadata": {},
   "source": [
    "See the distribution of consumption by the hour of the day. The creation of this chart might take a few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e7eee-c0ab-44e3-8cf8-81f1b9a348a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from hana_ml.visualizers.eda import EDAVisualizer\n",
    "f = plt.figure()\n",
    "ax1 = f.add_subplot(111) # 111 refers to 1x1 grid, 1st subplot\n",
    "eda = EDAVisualizer(ax1)\n",
    "ax, cont = eda.box_plot(data=df_rem_agg, column='CONSUMPTION_H', groupby='HOUR', vert=True, outliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae6dd9-afe9-44fd-9e3c-0bac9a027813",
   "metadata": {},
   "source": [
    "See the SELECT Statement that is behind the current hana_ml DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442af059-fe64-4fde-852e-e49c9a6e4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rem_agg.select_statement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f78f6d21-858b-4003-a104-dd4430357da6",
   "metadata": {},
   "source": [
    "Save the data structure, which includes the two calculated columns DATEHOUR and HOUR, as view for use in the next notebook. Only the semantics are saved, the data is not duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b961ac8-0c8e-483a-831f-6361ef0052f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_agg.save('V2_LUCERNEELECTRICITY', table_type='VIEW', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7bb98-a92f-4f41-abb3-6fca52f7880f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
