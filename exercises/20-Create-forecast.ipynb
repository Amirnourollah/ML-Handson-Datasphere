{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e4bc983-c537-4ecd-9f61-b64da15aa8e0",
   "metadata": {},
   "source": [
    "# Machine Learning with SAP Datasphere, Hands-On Workshop\n",
    "## Create first forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165fc1b-6a38-402c-a885-d9b9ee12b046",
   "metadata": {},
   "source": [
    "Retrieve the credentials to connect to SAP Datasphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc61e94-de9f-4ef0-a062-ef2861680f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = open('credentials.json', 'r')\n",
    "credentials = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6f915-95af-4c5b-9341-fbb7822a64d8",
   "metadata": {},
   "source": [
    "Establish a connection with SAP Datasphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7629d-a693-42e8-91fa-c90efac6da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hana_ml.dataframe as dataframe\n",
    "conn = dataframe.ConnectionContext(address  = credentials['hana_address'],\n",
    "                                   port     = credentials['hana_port'], \n",
    "                                   user     = credentials['hana_user'], \n",
    "                                   password = credentials['hana_password'], \n",
    "                                  )\n",
    "conn.connection.isconnected()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e3c400b-dcbf-4595-b146-c488aecc5fb4",
   "metadata": {},
   "source": [
    "Point a hana_ml DataFrame to the view in SAP Datasphere, which was created in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ddda-4b60-4a7e-a2fc-8a0411a47fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote = conn.table('V2_LUCERNEELECTRICITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9e5e0-909b-4f67-90a8-e821fce8c947",
   "metadata": {},
   "source": [
    "Retrieve and display a few rows of data from SAP Datasphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088778e-3534-4dc5-90b3-f8371dc867ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remote.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e36df402-24ae-4077-b66c-ef58d958a8d1",
   "metadata": {},
   "source": [
    "Split the data into training and test set. This will allow to train the Machine Learning model on one part of the data (df_rem_train) and to test the accuracy of its forecast on the test data (df_rem_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae3397-8cf3-4073-8e3a-4509823bb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_train = df_remote.filter('''DATEHOUR > '2022-01-01' AND \"DATEHOUR\" < '2023-06-25'  ''')\n",
    "df_rem_test = df_remote.filter('''\"DATEHOUR\" >='2023-06-25' AND DATEHOUR < '2023-06-27' ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52abcfe-ea37-4a5d-b078-4a41721beaff",
   "metadata": {},
   "source": [
    "Train the Machine Learning model on the training data. We use the AdditiveModelForecast algorithm, which is part of the Predictive Analysis Library in SAP HANA Cloud. This algorithm uses the same concept as Facebook's Prophet algorithm, which is very popular for time series forecasts. See the documentation on https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2023_2_QRC/en-US/pal/algorithms/hana_ml.algorithms.pal.tsa.additive_model_forecast.AdditiveModelForecast.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb892c2-c4e9-4be6-bc9d-ee46793c66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa.additive_model_forecast import AdditiveModelForecast\n",
    "amf = AdditiveModelForecast()\n",
    "amf.fit(data=df_rem_train.drop('HOUR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b9e4a-6124-4498-b433-95bb3fba38aa",
   "metadata": {},
   "source": [
    "Look at the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(amf.model_.select('MODEL_CONTENT').collect().iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587e079-1068-4ff1-ad36-8023d1d17a05",
   "metadata": {},
   "source": [
    "Predict the consumption for the time period of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14f8d2-e0c5-4164-ab08-d85fedfd4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_predicted = amf.predict(data=df_rem_test)\n",
    "df_rem_predicted.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef30409e-185d-4758-86ea-7436a3fc765f",
   "metadata": {},
   "source": [
    "Combine the known consumption of the test data with the prediction to assess the forecast accurarcy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ffb6c-143c-47ab-89d1-a4f7d49e9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_predicted = df_rem_test.set_index('DATEHOUR').join(df_rem_predicted.set_index('DATEHOUR'))\n",
    "df_rem_predicted.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "474f5aec-0097-45b2-95c5-032b2918fccd",
   "metadata": {},
   "source": [
    "Plot the predicted values versus the actual values to visually compare the actuals with the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a5227-f569-42d9-ac3e-189c6c8e3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_rem_predicted.sort(\"DATEHOUR\").collect()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(df_data['DATEHOUR'], df_data['YHAT'])\n",
    "plt.plot(df_data['DATEHOUR'], df_data['CONSUMPTION_H'])\n",
    "plt.fill_between(df_data['DATEHOUR'],df_data['YHAT_LOWER'], df_data['YHAT_UPPER'], alpha=.3)\n",
    "plt.legend(['Forecast', 'Actual'])\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a8e46cd-2ab0-44ed-b4e1-33ec9f11d9b8",
   "metadata": {},
   "source": [
    "Calculate an error metrics. We ask for the MAPE, which stands for \"Median Absolute Percentage Error\". Other error metrics are listed in https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2023_2_QRC/en-US/pal/algorithms/hana_ml.algorithms.pal.tsa.accuracy_measure.accuracy_measure.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fcd286-7c44-4966-922a-d1fb29aa18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal.tsa.accuracy_measure import accuracy_measure\n",
    "accuracy_measure(df_rem_predicted.select(['CONSUMPTION_H', 'YHAT']),\n",
    "evaluation_metric='mape').collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ff5be8c-d0a3-47d3-ba64-565ca69519d6",
   "metadata": {},
   "source": [
    "Combine the training dataset with the predicted data. This UNION of hana_ml DataFrames requires both to have the same structure. Hence the training data is extended to also contains the columns that hold the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb57939-6616-475d-823c-4d9c19c8d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_train = df_rem_train.select('*', ('NULL', 'YHAT'),\n",
    "                                  ('NULL', 'YHAT_LOWER'),\n",
    "                                  ('NULL', 'YHAT_UPPER')\n",
    "                                  )\n",
    "df_rem_all = df_rem_predicted.union(df_rem_train)\n",
    "df_rem_all.head(5).collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60c66056-573c-4d08-84ef-acd66602cada",
   "metadata": {},
   "source": [
    "Save the combined dataset as physical table to SAP Datasphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcfacc8-03c7-4cce-b6d6-43c3839f8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_all.save('LUCERNEELECTRICITY_FORECAST', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b8f45-51e8-418d-8fcf-ae206269a3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
